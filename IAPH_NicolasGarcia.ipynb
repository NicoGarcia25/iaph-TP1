{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Trabajo practico 1 IAPH Nicolas Garcia"
      ],
      "metadata": {
        "id": "JJu9qUFolEII"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "consigna: stop-words en el Mart√≠n Fierro\n",
        "\n",
        "Utilizar una de las bibliotecas ya mencionadas en otras tareas (PyPDF, PDFPlumber o PyMuPDF) para extraer s√≥lo el texto completo del Mart√≠n Fierro. Ignorar im√°genes, n√∫meros de p√°gina, √≠ndice.\n",
        "\n",
        "Procesar el texto para convertirlo todo a min√∫sculas y eliminar signos de puntuaci√≥n b√°sicos.\n",
        "\n",
        "Separar el texto en palabras individuales (tokenizaci√≥n).\n",
        "\n",
        "Identifique las stop-words usando la librer√≠a spacy. ¬øLogra identificar todas las stop-words? De no ser as√≠, indique cu√°les sumar√≠a."
      ],
      "metadata": {
        "id": "MeW-XYVxlWHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## primero instalamos pymupdf y spacy ‚¨á\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pRaelbHkYKAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf spacy\n",
        "!python -m spacy download es_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sU-yc7hCm1uG",
        "outputId": "fbffd1ef-b535-42c7-b1ae-82446647b3d1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.17.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# en este paso importamos las librerias que vamos a usar mas tarde y descargamos el pdf desde la url, cuando lo abrimos le pedimos que solo nos muestre texto entonces deja de haber imagenes, las imagenes pasan a estar en formato texto y son una url que eliminaremos mediante el re, asin mismo eliminamos los numeros, numeros romanos y los \"pagina\", por ultimo imprimimos a ver si funciono  üìö"
      ],
      "metadata": {
        "id": "RnRLjgEHuXrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "veRSqhJFUMTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "import requests\n",
        "import re\n",
        "\n",
        "# Descargar PDF\n",
        "url = \"https://www.argentina.gob.ar/sites/default/files/hernandez_jose_-_el_gaucho_martin_fierro.pdf\"\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "pdf_bytes = response.content\n",
        "\n",
        "texto_estrofas = \"\"\n",
        "\n",
        "with fitz.open(stream=pdf_bytes, filetype=\"pdf\") as pdf:\n",
        "    for page in pdf:\n",
        "        # Obtener texto del bloque tal cual\n",
        "        page_text = page.get_text(\"text\")\n",
        "\n",
        "        # divide en lineas\n",
        "        for line in page_text.splitlines():\n",
        "            stripped = line.strip()\n",
        "            if not stripped:\n",
        "                continue\n",
        "             #eliminamos numeros romanos que aparecen por capitulo\n",
        "            if re.fullmatch(r'[IVXLCDM]+', stripped, re.IGNORECASE):\n",
        "                continue\n",
        "            # eliminamos numeros de pagina\n",
        "            if re.fullmatch(r'\\d+', stripped):\n",
        "                continue\n",
        "            # esto elimina el \"pagina x\"\n",
        "            if re.search(r'(?i)p√°gina\\s*\\d+', stripped):\n",
        "                continue\n",
        "            # eliminamos URLs\n",
        "            if \"http\" in stripped.lower() or \"www.\" in stripped.lower():\n",
        "                continue\n",
        "            # conservar todo lo dem√°s, incluso t√≠tulos o l√≠neas cortas\n",
        "            texto_estrofas += stripped + \"\\n\"\n",
        "\n",
        "print(texto_estrofas[:700])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_Ojj_z5BvYE",
        "outputId": "1f424123-2bf3-4629-be03-91a340d88dfb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recursos de dominio p√∫blico\n",
            "El gaucho\n",
            "Mart√≠n Fierro\n",
            "Jos√© Hern√°ndez\n",
            "Jos√© Hern√°ndez\n",
            "El Gaucho Mart√≠n Fierro\n",
            "Jos√© Hern√°ndez (1834 - 1886)\n",
            "Im√°genes de dominio p√∫blico. Fuente:\n",
            "El Gaucho Mart√≠n Fierro\n",
            "Aqu√≠ me pongo a cantar\n",
            "al comp√°s de la vig√ºela,\n",
            "que el hombre que lo desvela\n",
            "una pena estrordinaria,\n",
            "como la ave solitaria\n",
            "con el cantar se consuela.\n",
            "Pido a los santos del cielo\n",
            "que ayuden mi pensamiento:\n",
            "les pido en este momento\n",
            "que voy a cantar mi historia\n",
            "me refresquen la memoria\n",
            "y aclaren mi entendimiento.\n",
            "Vengan santos milagrosos,\n",
            "vengan todos en mi ayuda,\n",
            "que la lengua se me a√±uda\n",
            "y se me turba la vista;\n",
            "pido a mi Dios que me asista\n",
            "en una ocasi√≥n tan ruda.\n",
            "Yo he visto muchos cantores,\n",
            "con fam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **‚úè** En este paso eliminamos los signos de puntuacion y transformamos todo a minusculas mediante .lower() y ''.join(c for c in texto_minusculas if c not in string.punctuation)\n"
      ],
      "metadata": {
        "id": "zk0O2fhcV2Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import string\n",
        "texto_minusculas = texto_estrofas.lower()\n",
        "sin_puntuacion = ''.join(c for c in texto_minusculas if c not in string.punctuation)\n",
        "\n",
        "print(sin_puntuacion[:80])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnT0URCqFHGs",
        "outputId": "e9cd0a3e-b47b-4074-8274-24771430db83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recursos de dominio p√∫blico\n",
            "el gaucho\n",
            "mart√≠n fierro\n",
            "jos√© hern√°ndez\n",
            "jos√© hern√°nde\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Para tokenizar las palabras dividimos el texto por cada espacio que hay con .split(), despues creamos una lista de palabras unicas y vamos recorriendo el textoe n busqueda de palabras individuales, las repetidas las pasamos y solo dejamos una vez en la lista cada una."
      ],
      "metadata": {
        "id": "PFpXcMqsWPFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separar palabras por espacios\n",
        "palabras = sin_puntuacion.split()\n",
        "\n",
        "# palabras √∫nicas manteniendo el orden\n",
        "palabras_unicas = []\n",
        "unicas = set()\n",
        "for palabra in palabras:\n",
        "    if palabra not in unicas:                   #busca en el texto palabras individuales y las pone en la lista,\n",
        "          unicas.add(palabra)                       # si estan repetidas las pasa de largo y si no esta la agrega\n",
        "          palabras_unicas.append(palabra)\n",
        "\n",
        "\n",
        "print(palabras_unicas[:20])  # primeras 20 palabras √∫nicas, en orden"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrbe0w04HX39",
        "outputId": "30a2d693-ed14-4cce-80c1-556ac7f7116e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['recursos', 'de', 'dominio', 'p√∫blico', 'el', 'gaucho', 'mart√≠n', 'fierro', 'jos√©', 'hern√°ndez', '1834', '1886', 'im√°genes', 'fuente', 'aqu√≠', 'me', 'pongo', 'a', 'cantar', 'al']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# este codigo nos analiza mediante spaCy las palabras que interpreta como stopwords, primero cargamos el modelo en espa√±ol (segunda linea) , despues le digo que texto quiero analizar y el doc me genera el analisis del texto que quiero analizar, despues el stopwords_spacy nos da las palabras que estamos buscando.\n",
        "# como algunas palabras no aparecen entre las mas comunes lo que hice fue buscarlas individualmente y como todas aparecieron podemos asumir que tomo bien todas las stopwords y no nos faltaria ninguna"
      ],
      "metadata": {
        "id": "CwZ0JhRJXOOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "texto= sin_puntuacion\n",
        "doc = nlp(texto)\n",
        "# lista de stopwords\n",
        "stopwords_spacy = [token.text for token in doc if token.is_stop]\n",
        "\n",
        "# ejemplo: primeras 20 stopwords encontradas\n",
        "print(stopwords_spacy[:20])\n",
        "print(\"ellos\" in nlp.Defaults.stop_words)\n",
        "print(\"bajo\" in nlp.Defaults.stop_words)  #con esto lo que hago es probar si estas stopwords estan tambien en el listado, con esto asumo que todas las palabras de su mismo tipo tambien estan siendo listadas\n",
        "print(\"tambi√©n\" in nlp.Defaults.stop_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AG7QkcpLPS0w",
        "outputId": "beea9c3b-ab61-430c-dd46-8e49ce4ba4a3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['de', 'el', 'el', 'de', 'el', 'aqu√≠', 'me', 'a', 'al', 'de', 'la', 'que', 'el', 'que', 'lo', 'una', 'como', 'la', 'con', 'el']\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}